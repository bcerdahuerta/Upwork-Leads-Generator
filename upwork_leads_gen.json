{"project":{"profile":{"name":"upwork_leads_gen","description":"Upwork web scraper to fill a spreadsheet with web scraping projects"},"commands":[{"father":"use","command":"{\"tipo\":\"0\",\"url\":\"https://www.upwork.com/search/jobs/t/1/?client_hires=0&q=web%20scraping&sort=recency\"}","option":"chrome","var":"","index":0,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"e86618db-4d28-0e4e-3f92-68dcf1189a7c","mode_live":true,"getvar":"","screenshot":"","data_":{"tipo":"0","url":"https://www.upwork.com/search/jobs/t/1/?client_hires=0&q=web%20scraping&sort=recency"},"execute_debbug":0,"img":"","message":"use chrome {\"tipo\":\"0\",\"url\":\"https://www.upwork.com/search/jobs/t/1/?client_hires=0&q=web%20scraping&sort=recency\"}","extra":[],"result":"True"},{"father":"execJs","command":"document.getElementByXPath = function(sValue) { var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null); if (a.snapshotLength > 0) { return a.snapshotItem(0); } };\ndocument.getElementByXPath('//*[@id=\"jobs-per-page\"]/div/ul/li[3]/a').click()","option":"","var":"","index":1,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"fcffb97e-f63c-a509-3d22-3043a3c0596c","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execjs  document.getElementByXPath = function(sValue) { var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null); if (a.snapshotLength > 0) { return a.snapshotItem(0); } };\ndocument.getElementByXPath('//*[@id=\"jobs-per-page\"]/div/ul/li[3]/a').click()","extra":[],"result":"True"},{"father":"wait","command":"5","option":"","var":"","index":2,"group":"system","execute":2,"if":"","children":[],"else":[],"id":"d946039a-7dac-378f-3888-b6c8c5622745","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"wait  5","extra":[],"result":"True"},{"father":"execJs","command":"\ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet titles = document.getElementsByXPath('//section//h4//a').map(x => x.innerText)\n\nreturn titles","option":"","var":"","index":3,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"0b8fb36f-be89-01ea-d7fe-c873b18bce4e","mode_live":true,"getvar":"titles","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execjs  \ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet titles = document.getElementsByXPath('//section//h4//a').map(x => x.innerText)\n\nreturn titles","extra":[],"result":"True"},{"father":"setVar","command":"{titles}.decode()","option":"","var":"titles","index":4,"group":"system","execute":2,"if":"","children":[],"else":[],"id":"587659fc-05f2-c963-92a1-7a954942bf11","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"setvar  b'[\\'Build Dashboard using Scraped Data from Coinmarketcap.com\\', \\'Developer needed to create \"scraping\" software to pull daily lawsuits filed in TX\\', \\'Data Entry and Web Scraping\\', \\'Se experto en web scraping\\', \\'Collect data from various webpages via Python script\\', \\'Web scraping Script\\', \\'Water utility database research\\', \\'Data scraping mywsba\\', \\'Data List of Sales Contacts for Engineering Consulting - HR Contacts\\', \\'Build a webscraper across multiple pages with an Excel Sheet as the output\\', \\'2 Python Developers needed for long term project.\\', \\'Online Data Search on Websites / Lead Generation / Data Mining / Web Scraping\\', \\'Database creation - no scraping\\', \\'Web Application for B2B Sourcing\\', \\'Web scrape\\', \\'Data mining specialist to find non for profit organizations\\', \\'Python developer for selenium\\', \\'Looking up info based of list of 2679 companies\\', \\'Login authentication checker\\', \\'Hiring data miner part//full time (M&A + Commercial Properties)\\', \\'Need data sources to be assessed for their functionality or attribute\\', \\'Python scraping bot\\', \\'Extensive Web Researcher needed to locate Social media Influencers details\\', \\'Data Mining Expert is Needed to Extract the User Data from Websites\\', \\'Web scrapping\\', \\'Collect the Company & Contact information\\', \\'Lead list builder needed for leads from linkedin\\', \\'Developer needed for Scraping a complicated live stream website\\', \\'Need to find merchant provider website is using\\', \\'Transfer Excel Spreadsheets onto a website\\', \\'Develop and Scrape Data from Website\\', \\'Lead Generation of US Shoe Importers\\', \\'Website scraping into excel multiple times per minute\\', \\'Developer needed to scrape university websites\\', \\'Looking for an Automation Expert\\', \\'Web Scraping using Python\\', \\'Benchmarking exercise for 6 countries\\', \\'Enrich contact data to sheet with only company data - marketing profiles within each company\\', \\'Generate a list of prospects/leads of companies using VOIP or PBX phone systems\\', \\'Parser SBB train schedule to Google Sheet\\', \\'eCommerce website scrape, with data output in Excel and image files\\', \\'Data Mining from multiple ecommerce sites\\', \\'Binance Smart Chain Bot for Sniping BEP20 Tokens & Pre-Launch Coins\\', \\'Data Extraction\\', \\'Build Web Scraper for Crexi.com\\', \\'Assistance with Scrapy, pulling data from nested pages\\', \\'Chrome extension to fetch Linkedin profile details\\', \\'Python programmer - data acquisition from API\\', \\'A Developer who can build Aliexpress scraper\\', \\'Web Scrapping In Excel\\']'.decode()","extra":[],"result":"True"},{"father":"execJs","command":"\ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet url = document.getElementsByXPath('//section//h4//a/@href').map(x => 'https://www.upwork.com'+x.value)\n\nreturn url","option":"","var":"","index":5,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"99ffc9b6-090d-79d7-a16c-8b93c7939660","mode_live":true,"getvar":"url","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execjs  \ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet url = document.getElementsByXPath('//section//h4//a/@href').map(x => 'https://www.upwork.com'+x.value)\n\nreturn url","extra":[],"result":"True"},{"father":"setVar","command":"{url}.decode()","option":"","var":"url","index":6,"group":"system","execute":2,"if":"","children":[],"else":[],"id":"de2ac009-840c-ad95-147e-71c46a6ff808","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"setvar  b\"['https://www.upwork.com/job/Build-Dashboard-using-Scraped-Data-from-Coinmarketcap-com_~01cee640682cd0bea8/', 'https://www.upwork.com/job/Developer-needed-create-quot-scraping-quot-software-pull-daily-lawsuits-filed_~01ea1d5a73c605ddc5/', 'https://www.upwork.com/job/Data-Entry-and-Web-Scraping_~019a79f57b4a2f3ebc/', 'https://www.upwork.com/job/experto-web-scraping_~01da6c70ae4771c4ae/', 'https://www.upwork.com/job/Collect-data-from-various-webpages-via-Python-script_~018838140d5e08ea98/', 'https://www.upwork.com/job/Web-scraping-Script_~01532ec8e6709bd331/', 'https://www.upwork.com/job/Water-utility-database-research_~010c4fb6461015d52b/', 'https://www.upwork.com/job/Data-scraping-mywsba_~0165516a6dcc7981a7/', 'https://www.upwork.com/job/Data-List-Sales-Contacts-for-Engineering-Consulting-Contacts_~01ce177d032674abc2/', 'https://www.upwork.com/job/Build-webscraper-across-multiple-pages-with-Excel-Sheet-the-output_~01bd5dd87a9a7137a5/', 'https://www.upwork.com/job/Python-Developers-needed-for-long-term-project_~01ef93e7618ea7b404/', 'https://www.upwork.com/job/Online-Data-Search-Websites-Lead-Generation-Data-Mining-Web-Scraping_~015831c9f9b2bfba1d/', 'https://www.upwork.com/job/Database-creation-scraping_~01bb7663c59a250661/', 'https://www.upwork.com/job/Web-Application-for-B2B-Sourcing_~019c73f1e447a753b4/', 'https://www.upwork.com/job/Web-scrape_~01c42d497a406ce328/', 'https://www.upwork.com/job/Data-mining-specialist-find-non-for-profit-organizations_~01359681ff924016bd/', 'https://www.upwork.com/job/Python-developer-for-selenium_~012229dea37eb81a7e/', 'https://www.upwork.com/job/Looking-info-based-list-2679-companies_~0171e18b028bc748b4/', 'https://www.upwork.com/job/Login-authentication-checker_~012ef6bfef3d1a1dfb/', 'https://www.upwork.com/job/Hiring-data-miner-part-full-time-amp-Commercial-Properties_~01f71c4b0e5ca9ef15/', 'https://www.upwork.com/job/Need-data-sources-assessed-for-their-functionality-attribute_~01f8653ac8d2396e75/', 'https://www.upwork.com/job/Python-scraping-bot_~0105cb2455226fa8a1/', 'https://www.upwork.com/job/Extensive-Web-Researcher-needed-locate-Social-media-Influencers-details_~01703b3a6a3418a8e8/', 'https://www.upwork.com/job/Data-Mining-Expert-Needed-Extract-the-User-Data-from-Websites_~0163eec5fbaffbd071/', 'https://www.upwork.com/job/Web-scrapping_~0152ba7a602adbddd1/', 'https://www.upwork.com/job/Collect-the-Company-amp-Contact-information_~01c265b8c8362a49fe/', 'https://www.upwork.com/job/Lead-list-builder-needed-for-leads-from-linkedin_~01fb7a666f85bbac04/', 'https://www.upwork.com/job/Developer-needed-for-Scraping-complicated-live-stream-website_~01e08a1f2da92c880c/', 'https://www.upwork.com/job/Need-find-merchant-provider-website-using_~01422776e3118935fd/', 'https://www.upwork.com/job/Transfer-Excel-Spreadsheets-onto-website_~016e3c5f7369d74158/', 'https://www.upwork.com/job/Develop-and-Scrape-Data-from-Website_~01ded517b4182811a8/', 'https://www.upwork.com/job/Lead-Generation-Shoe-Importers_~01b9bd794ccd171fab/', 'https://www.upwork.com/job/Website-scraping-into-excel-multiple-times-per-minute_~01e02a34be43beae1f/', 'https://www.upwork.com/job/Developer-needed-scrape-university-websites_~0144f50d8a7518f267/', 'https://www.upwork.com/job/Looking-for-Automation-Expert_~01dae72ba7c2f56cc7/', 'https://www.upwork.com/job/Web-Scraping-using-Python_~01293fb2f204565ead/', 'https://www.upwork.com/job/Benchmarking-exercise-for-countries_~014e5186f1dac07429/', 'https://www.upwork.com/job/Enrich-contact-data-sheet-with-only-company-data-marketing-profiles-within-each-company_~01e9605808bbb88a11/', 'https://www.upwork.com/job/Generate-list-prospects-leads-companies-using-VOIP-PBX-phone-systems_~01645737f7aa6bde0b/', 'https://www.upwork.com/job/Parser-SBB-train-schedule-Google-Sheet_~0104f72599f6a817fe/', 'https://www.upwork.com/job/eCommerce-website-scrape-with-data-output-Excel-and-image-files_~01b915b2af1ab34fdc/', 'https://www.upwork.com/job/Data-Mining-from-multiple-ecommerce-sites_~0103f148e5b55f18b9/', 'https://www.upwork.com/job/Binance-Smart-Chain-Bot-for-Sniping-BEP20-Tokens-amp-Pre-Launch-Coins_~015217d31f7d798e54/', 'https://www.upwork.com/job/Data-Extraction_~01600619cb779b8e54/', 'https://www.upwork.com/job/Build-Web-Scraper-for-Crexi-com_~013c7ea4ce64cac884/', 'https://www.upwork.com/job/Assistance-with-Scrapy-pulling-data-from-nested-pages_~01058f597cf2b1656c/', 'https://www.upwork.com/job/Chrome-extension-fetch-Linkedin-profile-details_~0158434f075a788bdc/', 'https://www.upwork.com/job/Python-programmer-data-acquisition-from-API_~0104ed6bd266566e99/', 'https://www.upwork.com/job/Developer-who-can-build-Aliexpress-scraper_~01038cea7fd580e0e2/', 'https://www.upwork.com/job/Web-Scrapping-Excel_~0120a0c2570e8d7480/']\".decode()","extra":[],"result":"True"},{"father":"execJs","command":"\ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet fixed_prices = document.getElementsByXPath('//span[@data-itemprop=\"baseSalary\"]').map(x => x.innerText)\n\nreturn fixed_prices","option":"","var":"","index":7,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"39a5d82f-f094-0778-28f6-ffc085f1793a","mode_live":true,"getvar":"fixed_prices","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execjs  \ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet fixed_prices = document.getElementsByXPath('//span[@data-itemprop=\"baseSalary\"]').map(x => x.innerText)\n\nreturn fixed_prices","extra":[],"result":"True"},{"father":"setVar","command":"{fixed_prices}.decode()","option":"","var":"fixed_prices","index":8,"group":"system","execute":2,"if":"","children":[],"else":[],"id":"035722e0-82ed-5cbb-0f2e-8284c7732e7d","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"setvar  b\"['$500', '$1.3K', '$80', '$20', '$150', '$500', '$180', '$5', '$150', '$600', '$15K', '$100', '$100', '$1K', '$450', '$20', '$50', '$200', '$500', '$100', '$30', '$200', '$20', '$20', '$5', '$800', '$300', '$20', '$73', '$100', '$200', '$20', '$500', '$200', '$1K', '$5', '$1.5K', '$150', '$500', '$200', '$300', '$1K', '$1K', '$5', '$200', '$15', '$150', '$5K', '$400', '$40']\".decode()","extra":[],"result":"True"},{"father":"execJs","command":"\ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet descriptions = document.getElementsByXPath('//span[@data-ng-bind-html=\"$ctrl.job.description\"]').map(x => x.innerText)\n\nreturn descriptions","option":"","var":"","index":9,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"173c6665-985e-2288-5878-a7168827c1ba","mode_live":true,"getvar":"descriptions","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execjs  \ndocument.getElementsByXPath = function(sValue){ var aResult = new Array();var a = this.evaluate(sValue, this, null, XPathResult.ORDERED_NODE_SNAPSHOT_TYPE, null);for ( var i = 0 ; i < a.snapshotLength ; i++ ){aResult.push(a.snapshotItem(i));}return aResult;};\n\nlet descriptions = document.getElementsByXPath('//span[@data-ng-bind-html=\"$ctrl.job.description\"]').map(x => x.innerText)\n\nreturn descriptions","extra":[],"result":"True"},{"father":"setVar","command":"{descriptions}.decode('latin-1')","option":"","var":"descriptions","index":10,"group":"system","execute":2,"if":"","children":[],"else":[],"id":"93be82c8-79f4-ae66-25af-ca36f8459d61","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"setvar  b'[\\'Hi - thanks for looking at the post. I would like to create a dashboard using scraped data from coinmarketcap.com Essentially, I would like to pull down every coin listed on the site and have a spreadsheet like interface where I can view the following columns: Name of Coin Ticker Price: Current trading price, 24 hour price change, 1 week price change etc... Market Cap: Basic Market Cap, Fully Diluted Market Cap Watchlist: How many watchlists is this on, 24 change, 7 day change, 30 day change, 90 day change (important to confirm if this is possible) Volume: 24 hour volume, 24 hour volume change, 1 week volume change etc... High / Low: 24 hour, 7 day, 30 day, 90 day, All time Supply: Circulating Supply, Total Supply I would like the list to refresh as often as once every 30 minutes (although if less frequent it may be fine) I would also like the dashboard to be filterable (i.e., I can filter coins that are on 500+ watchlists, over $100MM market cap, and increased in price by 25% in last 24 hours) Also I would like to be able to sort the coins on any of the dimensions above (even if a filter is being used - so if I had the filter above activated, I also then want to be able to sort that subset by market cap). The changes would all be in percentage. Each coin would be a separate row and category would be a separate column. Ideally this is not done in excel, but rather a more visual dashboard. I would also like access to the excel backup data if possible (but no worries if not) Let me know if you are interested in the project. Really appreciate your time!!\\', \"Need developer to help extract information on lawsuits filed daily in Texas. The information may come from various court websites OR from ReSearch Texas site. The types of information we need on the lawsuits DAILY includes: - Type of case - County filed - Plaintiff name - Plaintiff\\'s counsel/attorney - Defendant name - Defendant Address, City & State, Zip Code - Date lawsuit filed\", \"Require some research on top data integration software companies operating in Europe (Germany, France, UK, Switzerland) and North America (US & Canada). The research would comprise of three parts: 1. Pull out the top data integration software companies ( 20 companies to be precise). Look into their core offerings, their unique selling points, and is it an all-in-one tool or requires third party configurations. 2. All this information need to be inserted in to a spreadsheet, and perfectly organized and formatted. 3. Each and every bit of information needs to be verified. Your profile ratings, reviews, profile portfolios won\\'t impress me. If I find your proposal convincing, I will award you this job.\", \\'Se precisa experto que analice el proyecto y sepa encontrar una soluci\\xf3n adecuada para extraer esa informaci\\xf3n e implementarla en la web. 46 casas de apuestas de las que habr\\xe1 que recopilar informaci\\xf3n de eventos y cuotas , as\\xed como de las promociones del home.\\', \\'There are several pages like etherscan, bscscan, tokenfomo etc. From these sites the latest released coin needs to be fetched. The list of coins has to be stored in a spreadsheet (.csv). When running the script it should enter new values per coin. Sample: Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, now Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, yesterday Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, 2 days ago ...\\', \\'Script Developer, Looking for an experienced developer for a 1-3 weeks project. Develop a script to extract certain fields from an eCommerce website. the fields should be accessible from a user interface with options to filter. Fields attached.\\', \\'I need someone to put together a database of water utilities and cities that offer water service in Wyoming and Colorado. -Only utilities and cities with 50,000 or less water connections -information in database should include Utility/city name, Contact information for utility director and top level decision makers, number of connections, and if it is a city/town running the water department or if it is separate from city/town -research to be put into CSP/excel file\\', \\'this is a just data scraping work it includes section like family criminal you have to just select and proceed. I need this completed as soon as possible . please submit any past experience.\\', \\'We are looking to build a sales contact spreadsheets from the (link removed) website which lists by province: - Company Name - Province - HR Contacts - HR Contact Name - HR Contact Primary Email - Main Phone Number\\', \\'Build a simple web scraper to extract recurring fields like Number, and property information. Build the scraper so it goes through all pages - and recognizes when the final page has been hit. All data to be stored as an excel sheet. Multiple places to be scraped (but on the same website, so fields should be similar), so the scraper has to either take in a URL and scrape accordingly, or a unique scraper needs to be created for each instance (6 instances) You will be working with 2 product/project managers Usman and Uzair, who have built software products, Fintech products and consulted organizations on technology implementation. Our expectations and features will be very clear - and we are looking to work with someone who we can collaborate with and potentially have a long term working relationship with for future projects.\\', \"We are looking for 2 Python Developers for long term project. The level of the expertise should be: Senior or Expert. We need a proof of your work, so please provide projects links you\\'ve been working on. A general Python knowledge is a good base, but experience in Python AI, ML and DL are crucial. More info about the project will be passed to shortlisted candidates.\", \"We are searching for 3 kinds of companies in every country: 1. Robotics for Kids 2. Coding for Kids 3. Dance for Kids We need 3 part timers to collate information on this companies: from different countries allocated. This persons may do via \\'web-search\\', \\'facebook search\\' etc. collate into an excel spreadsheet would be enough. Since we are unable to monitor, we would like to offer to pay for every lead accumulated. I guess that would be most efficient. For every company researched and slotted into excel: you will be paid $0.20. Basically, in Singapore, my staff would need about 1 hour to accumulate 30 companies. If you have time to do this, you would benefit. But if you have little time: it would be difficult to be quite satisfied with this job. Working time period: 10th May 2021: till 31 May 2021. When the list is complete: we would do a random check on the authenticity of the contact before making payment . thank you Winston www.brickworks123.com\", \\'We need a database of firms that practice in Australia along with address, email address (not generic) of the lawyers in the firm and any other contact information. The size of the law firm (how many lawyers) to be added if known as well. This needs to be done without data-scraping software and via research.\\', \\'I am looking for a full-stack web developer who is just starting to learn and grow. Take a look at ermgsolutions.com. You will be working on this project. This will be just like foursource.com but it is directed towards the Bangladesh market only. Need it to be developed in Python. For the time being the template being used will be the design.\\', \\'Web Scrape for profiles for business on google and linkedin\\', \\'Need someone who has expert level of data/web scraping skills and can efficiently collate them in a sheet\\', \\'One page from with 24 Fields some are drop down some are radio button and reaming are copy paste. I need exe software which can carry data from excel file and paste it on the from in every fields.\\', \\'Take a pdf of 2,679 list of company names- look up each company up on the web- and just provide their website link and city and state of company location..\\', \\'Need script to check login details if correct or incorrect using Selenium or something similar.\\', \\'Were looking to data mine 1000 leads for M&A in US and UK as well as for commercial properties in UK using Nimbus Maps and spreadsheets preparing for mail merge campaigns and LinkedIn direkt messaging. Are you konform a challenge?\\', \\'You have to asses URLs/data sources provided in \"Source Sheet\" based upon parameters(To be assessed) column E to O\\', \"I need a bot to scrape behind a web3.js auth, the bot should find new listed project and retrieve basic data. I\\'m new to Python so you will have to also provide a view to wrap the endpoint into flask and deploy it, need help deploying it as well. Should be a simple bot if you are familiar with web3.js and scraping. I prefer that you use beautifull soup for scraping since that\\'s what I\\'m learning to work with. Thank you!\", \"Hi, I\\'m looking for web researching expert who can locate the best social media infuencers details. Those influencers should be from Twitter,FB,and Insta. Locate influencers from these categories: Education, Study, learning, Traveling, Leisure, and Tourism I need the following information about them: Name Social media username Followers link of social media contact no email Apply only if you can do this extensive research. I need someone with result-oriented and attention to details vision\", \"Hi, I\\'m looking for expert who can rigorously extract data from websites (meetup and eventbrite) as per requirements. I need mainly the Contact details of the end-users (organizers and attendees) specifically i.e first name, last name, categories, email, contact no, country, social media link, and other similar data available. Only apply if you\\'re a result-driven data mining expert and capable enough to provide all this information. Thanking You!\", \\'Hello, I want you to scrap the list of the companies available on LinkedIn and their profile links using request and beautiful soap. Please mention the time you will require for the work. I need this ASAP\\', \\'We are looking the expert who could gather the company information and contact with the right person for the projects we hope you are from EURO and USA, and we want to gather the following information: 1) contact informaiton name, tel, email,job title and more 2) company information ( name, web, industry, size and more) 3) projects information ( 4) data information more than 3000 companies 5) build relationship with target customer To be a best fit for this project you need: Ability to communicate clearly Dedication to meet project deadlines in a timely manner Write I am a human at the top of your proposal Attention to details Willingness to sign an NDA\\', \\'Lead Generation We are looking for an experienced lead list builder and Web/LinkedIn researcher to append 40 fans / blowers manufactures North America. The list shall be created in excell Sheets with a specific company phone number. All columns of the List have to be filled out: Companies (200 employees +) First Name Last Name Email Address LinkedIn Profile Departments: Engineering and Research & Development High level: VP Engineering, Director Engineering, R&D Leader, R&D Director Manager level: Design Manager, R&D Manager, Engineering Manager Entry/senior level: Design Analyst, Design Engineer, CFD engineer\\', \"Hello freelancers, there is a website https://www.radheexch.com/indianpoker. I want that live stream video to my website( only that video ) this website uses an IFrame of https://d2.fawk.app/#/splash-screen/RDE:happy.8DF9DAC7675076F23F56D4F70F143A23/9211?opentable=56767 you can also check the video here you need to scrape the source whatever you do I don\\'t know I just need this live video on my website check attached screenshot for more price is just a text can be change\", \\'I am looking to use the same merchant service as a website. I am unable to find the merchant provider they use. If you have an ability to find out the merchant service they use to accept credit card payments, please respond.\\', \"I\\'ve built a pretty big spreadsheet for a team on a data-related gaming platform. The problem is with these files, there is a security issue where the file can be sent from one person to the next, eliminating the advantage one would have by using the spreadsheet. What I want to do is convert all the functions into a website & possibly a web app & mobile app for: maths-based calculations web scraping based on data analysis after login interactive interface easy to use If anyone can help, it would be great.\", \\'Hi! Let\\\\\\'s say from the start that I don\\\\\\'t have much experience with computer science, so I leave you carte blanche on much of the design and programming. I intend to base the program on an external host of your choice (choose the best). My idea is to take advantage of the delays in the game of roulette, therefore not basing the probabilities on a mathematical basis, but on a historical basis (the same color / parity has never come out more than 32 times, and from these data I have derived probabilities) . The program in short is supposed to alert me to the seventh element of a sequence (color or parity) so that I can play starting from the ninth delay on the same sequence; in case the sequence continues I double the amount bet up to 5 times. Speaking of the technical aspect, the program collects data from one of these sites (web scraping): 888, leovegas, starcasin\\xf2, eurobet, goldbet (as far as I know you should be logged in the lobby) and from these 5 roulettes: ROULETTE OF VENICE SPEED ROULETTE VIP ROULETTE IMMERSIVE ROULETTE ROULETTE. The program then analyzes the data collected from the spins of the aforementioned roulette wheels and detects whether there is a sequence of colors or parity between the numbers analyzed. At this point, with a delay not exceeding 30 seconds, the program sends a notification on a telegram channel (id: -1001268239466) when a sequence of 7 equal spins is detected. The notification must advise on which roulette the sequence is and the type of sequence (eg \"Venezia Roulette 7 Nero\" - the notification must be in Italian so black = nero, red = rosso, even = pari, odd = dispari). Finally, every week the program sends the data report on the same telegram channel (tell me if this feature is feasible): the message must contain the history of the bets and whether they have been successful or not (considering valid the result starting from the ninth element of the sequence) As for the APIs, I\\\\\\'m not at all sure how they can be used in such a program.\\', \\'Need an expert Lead generation specialist to find 10,000 US based Shoe Importers. Specifications: - Company name - Company address - Supply Chain Manager/ International Supplier Relations Manager Name - Supply Chain Manager/ International Supplier Relations Manager Email Address List needs to be in excel format\\', \\'https://bet.hkjc.com/racing/pages/odds_wp.aspx?lang=en&date=2021-05-08&venue=ST&raceno=1 into an excel sheet every minute or less for at least 30 minutes continously\\', \\'Hello! I am looking for a detail-oriented developer with Microsoft Excel and Word and web scraping experience who can scrape email addresses of university staff members from publicly available websites. The deliverable is an Excel file of staff members email addresses and corresponding job titles that incorporates the below. The email addresses scraped would be used by my coauthors and I to conduct academic research. Details: - I would provide you with: (1) a Word file that lists university websites (approximately 10) that would need scraped for university staff email addresses. (2) a Word file of types of staff job titles to include and exclude. - I am looking for someone who can: *Identify web pages on provided websites that contain staff members email addresses and job titles. *Scrape staff members email addresses and job titles from those websites (approximately 10,000). *Provide a spreadsheet in Excel as follows: Each row corresponds to an individual staff member, and in columns provide their email address, job title, and university. Thank you, Catherine\\', \"I need a crawler I need an aggregator I need an automated emailer I need an automated form filler. I am looking for a variety of little scripts that can handle the project. It\\'s not complicated, to my limited knowledge, and certainly not groundbreaking. I\\'m looking to automate finding a certain kind of form and filling it in. This is not customer facing, and I don\\'t need it to be pretty, or elegant. I have a small video appended so you can meet me.\", \\'I am trying to scrape data from a website which requires login and the login is done on the main domain. Login process is done through different request and redirection is none through different request. I tried but I am not able to extract the information. you can use this link below to see my problem in detail stackoverflow.com/questions/67431281/how-to-scrape-data-from-a-website-which-requires-login-using-python?noredirect=1#comment119187464_67431281\\', \\'Looking for data and information on the internet, to build a report about hte exporting requirements to 6 different countries, and this includes answering the following questions: - what is the process of exporting a product for each country? and how much time does it take? - What is the required papers and how to get them? -What is the product-specific requirements (one product only). in terms of packaging, labeling, sizes, ...etc It should not take more than 3 weeks of work/ 4 -5 hours per day Thanks\\', \\'We have a data sheet of 1000 companies that we need to enrich with data on what marketing profiles works within these companies and what contact details we can get online on these profiles. Research could for instance be done by scraping company LinkedIn (find their employees working in marketing), looking at company websites and so forth. Whatever online research it takes to get the contact details. Looking for a freelancer who is ready to take on a large data set and enrich with this type of data through various methods of research.\\', \\'About us: Oztel is a technology service delivery company that offers services to businesses and residential customers. We offer VOIP, Cloud and technical solutions to businesses in Sydney, NSW. We\\\\\\'re looking to generate and increase the number of leads for our sales team. This project includes the following:  Find contact info of suitable prospects  Compile accurate list in Google Sheets or Microsoft Excel  Share your list of screened prospects and contact info with the sales team Target: Australia, NSW, Sydney Contact info need:  Name (Must be like this: \"John\" not: JOHN, JoHN, john)  Title  Company  Work email  Phone number (If available)  LinkedIn profile  Website This project requires: - Someone who can generate prospects who own companies, or head of IT in companies, who look after the phone systems. In your proposal, please share a brief summary of your experience, including a one-minute audio self-introduction. Important Notes*  Emails must be real emails, they will be checked using an email verification software.  In your application please provide the price per lead you can deliver us  In your proposal please provide a sample of 10 leads. Were looking for a hardworking, honest and detail-oriented individual. This is an ongoing job if hired your services will be used on an ongoing basis. Preferred qualifications: English level: Fluent Location: Ukraine, Philippines, Russia, Skills:  Data Mining  Data Scraping  Internet Research  Lead Generation  Spreadsheets  Web Scraping ----- Project Budget $50-$250 Example Industries List 1: Company Industry (5000 total, 1000 each) Telemarketing Medical Centers Online Retail Companies Service Delivery Companies Consulting Firms List 2: (5000, 1000 each) Lawyer Firms Medium Sized Companies Educational Institutions Manufacturing Companies Sales Companies List 3: 3000 (1000 each) Transportation companies Real Estate Companies Small businesses owners (any kind) I have attached the excel file template which you will have to populate. Please populate this sheet and do not create your own one.\\', \\'We need a creative service to a parsing schedule from the SBB train\\', \\'Im looking to scrape an eCommerce website for about 10 product types (URLs to be provided). In all I need data on approximately 3,000 web pages, including all product images. I need the details output to an Excel spreadsheet based on a template that I will provide. In outline the columns of the spreadsheet will be...  Thumbnails of the primary image.  Product Code  Product Description  Retail Price  Customer Review  File path of image 1  File path of image 2 The upwork should be a two stage/milestone scrape process ... Stage 1: Test scrape and output to Excel and image files of 1 product type. Payment for this milestone with the authorised subject to...  A check by myself that the data scraped and the images provided are correct.  Agreement to any changes found to be necessary to the data scraped and reported in new columns in the Excel spreadsheet Stage 2: Actual scrape, making data according to the revised spreadsheet format. Please let me know when you can do this work? ________________________________________ You will be asked to answer the following questions when submitting a proposal: 1. How often do you scrape eCommerce websites? 2. Can you scape websites outside the continent in which you are located? 3. Can you undertake a two stage scrape process as outlined in the work description? In your experience is this a good approach? Can you suggest an alternative?\\', \\'I need a csv file that contains many products from multiple websites. Most of the websites are originally Arabic but they provide also English. The most important thing is to assign each product by a specific identifier such as UUID ( such as iPhone 11 Pro Max 256 gb will be assigned an identifier that applies to the same product on all websites ) CSV file will contain ( Name of the product, Price of the product, Description, URL of the product, and URL of the product image ) It will be a large set of products 50,000+ products.\\', \\'Hi & Thank you for taking out your time to look at the opportunity we have This will be a challenging assignment but for the right candidate, it should be pretty straight-forward & has the potential to create additional revenue by supplying me with the full source code, so I have the ability to quickly connect to any wallet by signing or entering my private key into a config file (see bonus payment offer below) Im looking for someone to create a front-running sniper bot that uses the Binance Smart Chain API or node and detects when new liquidity is added to an AMM (automated market maker) pool on Pancakeswap v1/v2 (runs on the Binance Smart Chain, BEP20 network). Its paramount the bot is efficient in sacrificing high gas fees to be one of the first orders placed (front-run) The BOT would essentially: - Scan the blockchain and find transactions based on certain criteria (pending on the block aka mempool). It needs to detect and immediately execute a trade on the same second liquidity to is added to a token, according to my parameters - Front-run (specific trade volumes, slippage, and gas price) transactions by placing a buy order on the same block at the same time by setting a higher gas price. - Sell immediately in the next block right after the buy transaction on the front-ran block is completed. - Send BNB profit from trades to Trust Wallet address after every 4 successful trades. - I would like this to be connected to a Trust Wallet (Bonus Payment for adding MetaMask compatibility) - A simple UI for the bot where I can manage parameters such as : minimum amount of the trade, slippage tolerance, range or amount to put into trades for buy and sell orders, connection to the wallet, the token contract address (one or multiple contracts at the same time), gas price parameters. - A dashboard with all the trades done and where other features can be controlled. GUI would be extra, but the speed and process of the bot are preferred as order timing and placement is obviously the most important. I have a basic node available but will be willing to buy a better node if required. My knowledge is pretty dim on how this will all work which is why I would like an expert to take over but I will provide an example project upon request in case you would like to see or build off of it. If you know of any anti-bot features that will ensure it executes on block 1 that have been tested in the past I will increase payout by $500 upon completion & proof of testing Recap: A bot that detects when new liquidity is added to an AMM (automated market maker) pool on Pancakeswap (runs on Binance Smart Chain). The bot needs to detect it and immediately execute a trade according to my parameters. I need to be able to give the bots my own parameters such as: contract address, gas price, max. buying price of the token, selling price of the token, quantity of tokens to buy/sell. The interface needs to be easy to use. Full source code must be included with the ability to connect to any wallet by signing or entering my private key into the config file IMPORTANT: I would like the option to buy more of the same bot/code for others to use in my family. This project MUST be taken on by an experienced & competent developer/engineer, there will be additional bonuses for speed of completion & including the additional functionality mentioned above\\', \\'Data extraction. I need data for schools in NZ. School name School head Head phon No Email address URL\\', \\'Please create for us a web scraping tool that pulls data every 12 Hours from Crexi.com and uploads the data points to a Zoho Sheet (Excel or Google Sheet will work but Zoho Sheet Preferably). Upon entering Crexi, please use the Industrial Self Storage filter to find self storage units. We are only interested in properties located in the USA at this time. I have attached a sample EXCEL file outlining the fields we will be looking for. If you find additional fields are available, please add them accordingly. You do not need to sort by price point or CAP rate  we are wanting to look at all of these deals. The tool should be able to open up each property and pull all data into the spreadsheet. Some properties have additional field values  please include each of those fields as columns for the sheet. Can you please add the link to the property as a field as well .\\', \"Hi! I am new to Scrapy and I\\'m having issues managing the yields and callbacks while navigating multiple pages. For example, I will have multiple links such as this - alapark.com/parks/bladon-springs-state-park. I will have to go through the page content and the links on the page before moving on to other urls. I will share an .ipynb notebook with the code I\\'ve written so far. I expect you to guide me through the solution over a video call. This shouldn\\'t take long for someone experienced with Scrapy. I am looking to hear someone immediately. Please don\\'t apply unless you are a Scrapy expert. Start your proposal with the word \\'pumpkin\\' or else it will be ignored.\", \\'I want to build a simple chrome extension through which we can fetch the user profile data from Linkedin and group them under names. We want to fetch the following data: Name Email - if possible Contact - if possible Location Designation Company\\', \\'We are looking for someone who would be able to help us with 3-7 (probably more in the future) API and create conectors for it. Then create Python scripts to automatically download and save data to databases via API. Specifically, we need help with these systems: - Google ADs (keyword and campaign data) - Facebook ADs (campaign data from FB) - Instagram API - Adobe Analytics (analytical data about website traffic and performance) - Google Analytics (analytical data about website traffic and performance) It is not necessary to perform all the mentioned systems, it is possible to agree on one or even several parts, from which, of course, the price will depend.\\', \\'I need a person who can scrape Aliexpress products info with requiremnts below - Scrape by category - Able to extract all products per category (currently Aliexpress limit showing pages per category) - Running multi-thread - Bypass blockage by using proxy API - The tool must scrape at least 4 million products a day - Save data to mongoDB, filter duplication while importing\\', \\'We are looking for the services of a Web Scraper. Candidates with relevant experience are encouraged to apply. Other Information will be provided at hiring time\\']'.decode('latin-1')","extra":[],"result":"True"},{"father":"execScriptPython","command":"import pandas as pd\n\ndf = pd.DataFrame({\n  \"Title\": eval(GetVar('titles')),\n  \"Description\": eval(GetVar('descriptions')),\n  \"Fixed_Price\": eval(GetVar('fixed_prices')),\n  \"URL\": eval(GetVar('url'))\n })\nprint(df)\n\ndf.to_csv(r'C:\\Users\\bisma\\OneDrive\\Escritorio\\Bismarck\\Bismarck\\Upwork\\projects.csv', index=False)","option":"","var":"","index":11,"group":"scripts","execute":2,"if":"","children":[],"else":[],"id":"cd79048f-ff61-a845-1fda-53d75066afc2","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":"","message":"execscriptpython  import pandas as pd\n\ndf = pd.DataFrame({\n  \"Title\": eval(GetVar('titles')),\n  \"Description\": eval(GetVar('descriptions')),\n  \"Fixed_Price\": eval(GetVar('fixed_prices')),\n  \"URL\": eval(GetVar('url'))\n })\nprint(df)\n\ndf.to_csv(r'C:\\Users\\bisma\\OneDrive\\Escritorio\\Bismarck\\Bismarck\\Upwork\\projects.csv', index=False)","extra":[],"result":"True"},{"father":"killdriver","command":"","option":"","var":"","index":12,"group":"web","execute":2,"if":"","children":[],"else":[],"id":"2599a8b1-0417-726f-4f04-7c1546a241e1","mode_live":true,"getvar":"","extra_data":null,"screenshot":"","execute_debbug":0,"img":""}],"vars":[{"name":"test","data":"[]","type":"string","collapse":true,"$$hashKey":"object:995"},{"name":"titles","data":"['Build Dashboard using Scraped Data from Coinmarketcap.com', 'Developer needed to create \"scraping\" software to pull daily lawsuits filed in TX', 'Data Entry and Web Scraping', 'Se experto en web scraping', 'Collect data from various webpages via Python script', 'Web scraping Script', 'Water utility database research', 'Data scraping mywsba', 'Data List of Sales Contacts for Engineering Consulting - HR Contacts', 'Build a webscraper across multiple pages with an Excel Sheet as the output', '2 Python Developers needed for long term project.', 'Online Data Search on Websites / Lead Generation / Data Mining / Web Scraping', 'Database creation - no scraping', 'Web Application for B2B Sourcing', 'Web scrape', 'Data mining specialist to find non for profit organizations', 'Python developer for selenium', 'Looking up info based of list of 2679 companies', 'Login authentication checker', 'Hiring data miner part//full time (M&A + Commercial Properties)', 'Need data sources to be assessed for their functionality or attribute', 'Python scraping bot', 'Extensive Web Researcher needed to locate Social media Influencers details', 'Data Mining Expert is Needed to Extract the User Data from Websites', 'Web scrapping', 'Collect the Company & Contact information', 'Lead list builder needed for leads from linkedin', 'Developer needed for Scraping a complicated live stream website', 'Need to find merchant provider website is using', 'Transfer Excel Spreadsheets onto a website', 'Develop and Scrape Data from Website', 'Lead Generation of US Shoe Importers', 'Website scraping into excel multiple times per minute', 'Developer needed to scrape university websites', 'Looking for an Automation Expert', 'Web Scraping using Python', 'Benchmarking exercise for 6 countries', 'Enrich contact data to sheet with only company data - marketing profiles within each company', 'Generate a list of prospects/leads of companies using VOIP or PBX phone systems', 'Parser SBB train schedule to Google Sheet', 'eCommerce website scrape, with data output in Excel and image files', 'Data Mining from multiple ecommerce sites', 'Binance Smart Chain Bot for Sniping BEP20 Tokens & Pre-Launch Coins', 'Data Extraction', 'Build Web Scraper for Crexi.com', 'Assistance with Scrapy, pulling data from nested pages', 'Chrome extension to fetch Linkedin profile details', 'Python programmer - data acquisition from API', 'A Developer who can build Aliexpress scraper', 'Web Scrapping In Excel']","type":"string","collapse":true,"$$hashKey":"object:996"},{"name":"fixed_prices","data":"['$500', '$1.3K', '$80', '$20', '$150', '$500', '$180', '$5', '$150', '$600', '$15K', '$100', '$100', '$1K', '$450', '$20', '$50', '$200', '$500', '$100', '$30', '$200', '$20', '$20', '$5', '$800', '$300', '$20', '$73', '$100', '$200', '$20', '$500', '$200', '$1K', '$5', '$1.5K', '$150', '$500', '$200', '$300', '$1K', '$1K', '$5', '$200', '$15', '$150', '$5K', '$400', '$40']","type":"string","collapse":true,"$$hashKey":"object:997"},{"name":"descriptions","data":"['Hi - thanks for looking at the post. I would like to create a dashboard using scraped data from coinmarketcap.com Essentially, I would like to pull down every coin listed on the site and have a spreadsheet like interface where I can view the following columns: Name of Coin Ticker Price: Current trading price, 24 hour price change, 1 week price change etc... Market Cap: Basic Market Cap, Fully Diluted Market Cap Watchlist: How many watchlists is this on, 24 change, 7 day change, 30 day change, 90 day change (important to confirm if this is possible) Volume: 24 hour volume, 24 hour volume change, 1 week volume change etc... High / Low: 24 hour, 7 day, 30 day, 90 day, All time Supply: Circulating Supply, Total Supply I would like the list to refresh as often as once every 30 minutes (although if less frequent it may be fine) I would also like the dashboard to be filterable (i.e., I can filter coins that are on 500+ watchlists, over $100MM market cap, and increased in price by 25% in last 24 hours) Also I would like to be able to sort the coins on any of the dimensions above (even if a filter is being used - so if I had the filter above activated, I also then want to be able to sort that subset by market cap). The changes would all be in percentage. Each coin would be a separate row and category would be a separate column. Ideally this is not done in excel, but rather a more visual dashboard. I would also like access to the excel backup data if possible (but no worries if not) Let me know if you are interested in the project. Really appreciate your time!!', \"Need developer to help extract information on lawsuits filed daily in Texas. The information may come from various court websites OR from ReSearch Texas site. The types of information we need on the lawsuits DAILY includes: - Type of case - County filed - Plaintiff name - Plaintiff's counsel/attorney - Defendant name - Defendant Address, City & State, Zip Code - Date lawsuit filed\", \"Require some research on top data integration software companies operating in Europe (Germany, France, UK, Switzerland) and North America (US & Canada). The research would comprise of three parts: 1. Pull out the top data integration software companies ( 20 companies to be precise). Look into their core offerings, their unique selling points, and is it an all-in-one tool or requires third party configurations. 2. All this information need to be inserted in to a spreadsheet, and perfectly organized and formatted. 3. Each and every bit of information needs to be verified. Your profile ratings, reviews, profile portfolios won't impress me. If I find your proposal convincing, I will award you this job.\", 'Se precisa experto que analice el proyecto y sepa encontrar una solucin adecuada para extraer esa informacin e implementarla en la web. 46 casas de apuestas de las que habr que recopilar informacin de eventos y cuotas , as como de las promociones del home.', 'There are several pages like etherscan, bscscan, tokenfomo etc. From these sites the latest released coin needs to be fetched. The list of coins has to be stored in a spreadsheet (.csv). When running the script it should enter new values per coin. Sample: Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, now Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, yesterday Coin, Symbol, Contract, Current holders, change holders in %, Current price, change price in %, 2 days ago ...', 'Script Developer, Looking for an experienced developer for a 1-3 weeks project. Develop a script to extract certain fields from an eCommerce website. the fields should be accessible from a user interface with options to filter. Fields attached.', 'I need someone to put together a database of water utilities and cities that offer water service in Wyoming and Colorado. -Only utilities and cities with 50,000 or less water connections -information in database should include Utility/city name, Contact information for utility director and top level decision makers, number of connections, and if it is a city/town running the water department or if it is separate from city/town -research to be put into CSP/excel file', 'this is a just data scraping work it includes section like family criminal you have to just select and proceed. I need this completed as soon as possible . please submit any past experience.', 'We are looking to build a sales contact spreadsheets from the (link removed) website which lists by province: - Company Name - Province - HR Contacts - HR Contact Name - HR Contact Primary Email - Main Phone Number', 'Build a simple web scraper to extract recurring fields like Number, and property information. Build the scraper so it goes through all pages - and recognizes when the final page has been hit. All data to be stored as an excel sheet. Multiple places to be scraped (but on the same website, so fields should be similar), so the scraper has to either take in a URL and scrape accordingly, or a unique scraper needs to be created for each instance (6 instances) You will be working with 2 product/project managers Usman and Uzair, who have built software products, Fintech products and consulted organizations on technology implementation. Our expectations and features will be very clear - and we are looking to work with someone who we can collaborate with and potentially have a long term working relationship with for future projects.', \"We are looking for 2 Python Developers for long term project. The level of the expertise should be: Senior or Expert. We need a proof of your work, so please provide projects links you've been working on. A general Python knowledge is a good base, but experience in Python AI, ML and DL are crucial. More info about the project will be passed to shortlisted candidates.\", \"We are searching for 3 kinds of companies in every country: 1. Robotics for Kids 2. Coding for Kids 3. Dance for Kids We need 3 part timers to collate information on this companies: from different countries allocated. This persons may do via 'web-search', 'facebook search' etc. collate into an excel spreadsheet would be enough. Since we are unable to monitor, we would like to offer to pay for every lead accumulated. I guess that would be most efficient. For every company researched and slotted into excel: you will be paid $0.20. Basically, in Singapore, my staff would need about 1 hour to accumulate 30 companies. If you have time to do this, you would benefit. But if you have little time: it would be difficult to be quite satisfied with this job. Working time period: 10th May 2021: till 31 May 2021. When the list is complete: we would do a random check on the authenticity of the contact before making payment . thank you Winston www.brickworks123.com\", 'We need a database of firms that practice in Australia along with address, email address (not generic) of the lawyers in the firm and any other contact information. The size of the law firm (how many lawyers) to be added if known as well. This needs to be done without data-scraping software and via research.', 'I am looking for a full-stack web developer who is just starting to learn and grow. Take a look at ermgsolutions.com. You will be working on this project. This will be just like foursource.com but it is directed towards the Bangladesh market only. Need it to be developed in Python. For the time being the template being used will be the design.', 'Web Scrape for profiles for business on google and linkedin', 'Need someone who has expert level of data/web scraping skills and can efficiently collate them in a sheet', 'One page from with 24 Fields some are drop down some are radio button and reaming are copy paste. I need exe software which can carry data from excel file and paste it on the from in every fields.', 'Take a pdf of 2,679 list of company names- look up each company up on the web- and just provide their website link and city and state of company location..', 'Need script to check login details if correct or incorrect using Selenium or something similar.', 'Were looking to data mine 1000 leads for M&A in US and UK as well as for commercial properties in UK using Nimbus Maps and spreadsheets preparing for mail merge campaigns and LinkedIn direkt messaging. Are you konform a challenge?', 'You have to asses URLs/data sources provided in \"Source Sheet\" based upon parameters(To be assessed) column E to O', \"I need a bot to scrape behind a web3.js auth, the bot should find new listed project and retrieve basic data. I'm new to Python so you will have to also provide a view to wrap the endpoint into flask and deploy it, need help deploying it as well. Should be a simple bot if you are familiar with web3.js and scraping. I prefer that you use beautifull soup for scraping since that's what I'm learning to work with. Thank you!\", \"Hi, I'm looking for web researching expert who can locate the best social media infuencers details. Those influencers should be from Twitter,FB,and Insta. Locate influencers from these categories: Education, Study, learning, Traveling, Leisure, and Tourism I need the following information about them: Name Social media username Followers link of social media contact no email Apply only if you can do this extensive research. I need someone with result-oriented and attention to details vision\", \"Hi, I'm looking for expert who can rigorously extract data from websites (meetup and eventbrite) as per requirements. I need mainly the Contact details of the end-users (organizers and attendees) specifically i.e first name, last name, categories, email, contact no, country, social media link, and other similar data available. Only apply if you're a result-driven data mining expert and capable enough to provide all this information. Thanking You!\", 'Hello, I want you to scrap the list of the companies available on LinkedIn and their profile links using request and beautiful soap. Please mention the time you will require for the work. I need this ASAP', 'We are looking the expert who could gather the company information and contact with the right person for the projects we hope you are from EURO and USA, and we want to gather the following information: 1) contact informaiton name, tel, email,job title and more 2) company information ( name, web, industry, size and more) 3) projects information ( 4) data information more than 3000 companies 5) build relationship with target customer To be a best fit for this project you need: Ability to communicate clearly Dedication to meet project deadlines in a timely manner Write I am a human at the top of your proposal Attention to details Willingness to sign an NDA', 'Lead Generation We are looking for an experienced lead list builder and Web/LinkedIn researcher to append 40 fans / blowers manufactures North America. The list shall be created in excell Sheets with a specific company phone number. All columns of the List have to be filled out: Companies (200 employees +) First Name Last Name Email Address LinkedIn Profile Departments: Engineering and Research & Development High level: VP Engineering, Director Engineering, R&D Leader, R&D Director Manager level: Design Manager, R&D Manager, Engineering Manager Entry/senior level: Design Analyst, Design Engineer, CFD engineer', \"Hello freelancers, there is a website https://www.radheexch.com/indianpoker. I want that live stream video to my website( only that video ) this website uses an IFrame of https://d2.fawk.app/#/splash-screen/RDE:happy.8DF9DAC7675076F23F56D4F70F143A23/9211?opentable=56767 you can also check the video here you need to scrape the source whatever you do I don't know I just need this live video on my website check attached screenshot for more price is just a text can be change\", 'I am looking to use the same merchant service as a website. I am unable to find the merchant provider they use. If you have an ability to find out the merchant service they use to accept credit card payments, please respond.', \"I've built a pretty big spreadsheet for a team on a data-related gaming platform. The problem is with these files, there is a security issue where the file can be sent from one person to the next, eliminating the advantage one would have by using the spreadsheet. What I want to do is convert all the functions into a website & possibly a web app & mobile app for: maths-based calculations web scraping based on data analysis after login interactive interface easy to use If anyone can help, it would be great.\", 'Hi! Let\\'s say from the start that I don\\'t have much experience with computer science, so I leave you carte blanche on much of the design and programming. I intend to base the program on an external host of your choice (choose the best). My idea is to take advantage of the delays in the game of roulette, therefore not basing the probabilities on a mathematical basis, but on a historical basis (the same color / parity has never come out more than 32 times, and from these data I have derived probabilities) . The program in short is supposed to alert me to the seventh element of a sequence (color or parity) so that I can play starting from the ninth delay on the same sequence; in case the sequence continues I double the amount bet up to 5 times. Speaking of the technical aspect, the program collects data from one of these sites (web scraping): 888, leovegas, starcasin, eurobet, goldbet (as far as I know you should be logged in the lobby) and from these 5 roulettes: ROULETTE OF VENICE SPEED ROULETTE VIP ROULETTE IMMERSIVE ROULETTE ROULETTE. The program then analyzes the data collected from the spins of the aforementioned roulette wheels and detects whether there is a sequence of colors or parity between the numbers analyzed. At this point, with a delay not exceeding 30 seconds, the program sends a notification on a telegram channel (id: -1001268239466) when a sequence of 7 equal spins is detected. The notification must advise on which roulette the sequence is and the type of sequence (eg \"Venezia Roulette 7 Nero\" - the notification must be in Italian so black = nero, red = rosso, even = pari, odd = dispari). Finally, every week the program sends the data report on the same telegram channel (tell me if this feature is feasible): the message must contain the history of the bets and whether they have been successful or not (considering valid the result starting from the ninth element of the sequence) As for the APIs, I\\'m not at all sure how they can be used in such a program.', 'Need an expert Lead generation specialist to find 10,000 US based Shoe Importers. Specifications: - Company name - Company address - Supply Chain Manager/ International Supplier Relations Manager Name - Supply Chain Manager/ International Supplier Relations Manager Email Address List needs to be in excel format', 'https://bet.hkjc.com/racing/pages/odds_wp.aspx?lang=en&date=2021-05-08&venue=ST&raceno=1 into an excel sheet every minute or less for at least 30 minutes continously', 'Hello! I am looking for a detail-oriented developer with Microsoft Excel and Word and web scraping experience who can scrape email addresses of university staff members from publicly available websites. The deliverable is an Excel file of staff members email addresses and corresponding job titles that incorporates the below. The email addresses scraped would be used by my coauthors and I to conduct academic research. Details: - I would provide you with: (1) a Word file that lists university websites (approximately 10) that would need scraped for university staff email addresses. (2) a Word file of types of staff job titles to include and exclude. - I am looking for someone who can: *Identify web pages on provided websites that contain staff members email addresses and job titles. *Scrape staff members email addresses and job titles from those websites (approximately 10,000). *Provide a spreadsheet in Excel as follows: Each row corresponds to an individual staff member, and in columns provide their email address, job title, and university. Thank you, Catherine', \"I need a crawler I need an aggregator I need an automated emailer I need an automated form filler. I am looking for a variety of little scripts that can handle the project. It's not complicated, to my limited knowledge, and certainly not groundbreaking. I'm looking to automate finding a certain kind of form and filling it in. This is not customer facing, and I don't need it to be pretty, or elegant. I have a small video appended so you can meet me.\", 'I am trying to scrape data from a website which requires login and the login is done on the main domain. Login process is done through different request and redirection is none through different request. I tried but I am not able to extract the information. you can use this link below to see my problem in detail stackoverflow.com/questions/67431281/how-to-scrape-data-from-a-website-which-requires-login-using-python?noredirect=1#comment119187464_67431281', 'Looking for data and information on the internet, to build a report about hte exporting requirements to 6 different countries, and this includes answering the following questions: - what is the process of exporting a product for each country? and how much time does it take? - What is the required papers and how to get them? -What is the product-specific requirements (one product only). in terms of packaging, labeling, sizes, ...etc It should not take more than 3 weeks of work/ 4 -5 hours per day Thanks', 'We have a data sheet of 1000 companies that we need to enrich with data on what marketing profiles works within these companies and what contact details we can get online on these profiles. Research could for instance be done by scraping company LinkedIn (find their employees working in marketing), looking at company websites and so forth. Whatever online research it takes to get the contact details. Looking for a freelancer who is ready to take on a large data set and enrich with this type of data through various methods of research.', 'About us: Oztel is a technology service delivery company that offers services to businesses and residential customers. We offer VOIP, Cloud and technical solutions to businesses in Sydney, NSW. We\\'re looking to generate and increase the number of leads for our sales team. This project includes the following:  Find contact info of suitable prospects  Compile accurate list in Google Sheets or Microsoft Excel  Share your list of screened prospects and contact info with the sales team Target: Australia, NSW, Sydney Contact info need:  Name (Must be like this: \"John\" not: JOHN, JoHN, john)  Title  Company  Work email  Phone number (If available)  LinkedIn profile  Website This project requires: - Someone who can generate prospects who own companies, or head of IT in companies, who look after the phone systems. In your proposal, please share a brief summary of your experience, including a one-minute audio self-introduction. Important Notes*  Emails must be real emails, they will be checked using an email verification software.  In your application please provide the price per lead you can deliver us  In your proposal please provide a sample of 10 leads. Were looking for a hardworking, honest and detail-oriented individual. This is an ongoing job if hired your services will be used on an ongoing basis. Preferred qualifications: English level: Fluent Location: Ukraine, Philippines, Russia, Skills:  Data Mining  Data Scraping  Internet Research  Lead Generation  Spreadsheets  Web Scraping ----- Project Budget $50-$250 Example Industries List 1: Company Industry (5000 total, 1000 each) Telemarketing Medical Centers Online Retail Companies Service Delivery Companies Consulting Firms List 2: (5000, 1000 each) Lawyer Firms Medium Sized Companies Educational Institutions Manufacturing Companies Sales Companies List 3: 3000 (1000 each) Transportation companies Real Estate Companies Small businesses owners (any kind) I have attached the excel file template which you will have to populate. Please populate this sheet and do not create your own one.', 'We need a creative service to a parsing schedule from the SBB train', 'Im looking to scrape an eCommerce website for about 10 product types (URLs to be provided). In all I need data on approximately 3,000 web pages, including all product images. I need the details output to an Excel spreadsheet based on a template that I will provide. In outline the columns of the spreadsheet will be...  Thumbnails of the primary image.  Product Code  Product Description  Retail Price  Customer Review  File path of image 1  File path of image 2 The upwork should be a two stage/milestone scrape process ... Stage 1: Test scrape and output to Excel and image files of 1 product type. Payment for this milestone with the authorised subject to...  A check by myself that the data scraped and the images provided are correct.  Agreement to any changes found to be necessary to the data scraped and reported in new columns in the Excel spreadsheet Stage 2: Actual scrape, making data according to the revised spreadsheet format. Please let me know when you can do this work? ________________________________________ You will be asked to answer the following questions when submitting a proposal: 1. How often do you scrape eCommerce websites? 2. Can you scape websites outside the continent in which you are located? 3. Can you undertake a two stage scrape process as outlined in the work description? In your experience is this a good approach? Can you suggest an alternative?', 'I need a csv file that contains many products from multiple websites. Most of the websites are originally Arabic but they provide also English. The most important thing is to assign each product by a specific identifier such as UUID ( such as iPhone 11 Pro Max 256 gb will be assigned an identifier that applies to the same product on all websites ) CSV file will contain ( Name of the product, Price of the product, Description, URL of the product, and URL of the product image ) It will be a large set of products 50,000+ products.', 'Hi & Thank you for taking out your time to look at the opportunity we have This will be a challenging assignment but for the right candidate, it should be pretty straight-forward & has the potential to create additional revenue by supplying me with the full source code, so I have the ability to quickly connect to any wallet by signing or entering my private key into a config file (see bonus payment offer below) Im looking for someone to create a front-running sniper bot that uses the Binance Smart Chain API or node and detects when new liquidity is added to an AMM (automated market maker) pool on Pancakeswap v1/v2 (runs on the Binance Smart Chain, BEP20 network). Its paramount the bot is efficient in sacrificing high gas fees to be one of the first orders placed (front-run) The BOT would essentially: - Scan the blockchain and find transactions based on certain criteria (pending on the block aka mempool). It needs to detect and immediately execute a trade on the same second liquidity to is added to a token, according to my parameters - Front-run (specific trade volumes, slippage, and gas price) transactions by placing a buy order on the same block at the same time by setting a higher gas price. - Sell immediately in the next block right after the buy transaction on the front-ran block is completed. - Send BNB profit from trades to Trust Wallet address after every 4 successful trades. - I would like this to be connected to a Trust Wallet (Bonus Payment for adding MetaMask compatibility) - A simple UI for the bot where I can manage parameters such as : minimum amount of the trade, slippage tolerance, range or amount to put into trades for buy and sell orders, connection to the wallet, the token contract address (one or multiple contracts at the same time), gas price parameters. - A dashboard with all the trades done and where other features can be controlled. GUI would be extra, but the speed and process of the bot are preferred as order timing and placement is obviously the most important. I have a basic node available but will be willing to buy a better node if required. My knowledge is pretty dim on how this will all work which is why I would like an expert to take over but I will provide an example project upon request in case you would like to see or build off of it. If you know of any anti-bot features that will ensure it executes on block 1 that have been tested in the past I will increase payout by $500 upon completion & proof of testing Recap: A bot that detects when new liquidity is added to an AMM (automated market maker) pool on Pancakeswap (runs on Binance Smart Chain). The bot needs to detect it and immediately execute a trade according to my parameters. I need to be able to give the bots my own parameters such as: contract address, gas price, max. buying price of the token, selling price of the token, quantity of tokens to buy/sell. The interface needs to be easy to use. Full source code must be included with the ability to connect to any wallet by signing or entering my private key into the config file IMPORTANT: I would like the option to buy more of the same bot/code for others to use in my family. This project MUST be taken on by an experienced & competent developer/engineer, there will be additional bonuses for speed of completion & including the additional functionality mentioned above', 'Data extraction. I need data for schools in NZ. School name School head Head phon No Email address URL', 'Please create for us a web scraping tool that pulls data every 12 Hours from Crexi.com and uploads the data points to a Zoho Sheet (Excel or Google Sheet will work but Zoho Sheet Preferably). Upon entering Crexi, please use the Industrial Self Storage filter to find self storage units. We are only interested in properties located in the USA at this time. I have attached a sample EXCEL file outlining the fields we will be looking for. If you find additional fields are available, please add them accordingly. You do not need to sort by price point or CAP rate  we are wanting to look at all of these deals. The tool should be able to open up each property and pull all data into the spreadsheet. Some properties have additional field values  please include each of those fields as columns for the sheet. Can you please add the link to the property as a field as well .', \"Hi! I am new to Scrapy and I'm having issues managing the yields and callbacks while navigating multiple pages. For example, I will have multiple links such as this - alapark.com/parks/bladon-springs-state-park. I will have to go through the page content and the links on the page before moving on to other urls. I will share an .ipynb notebook with the code I've written so far. I expect you to guide me through the solution over a video call. This shouldn't take long for someone experienced with Scrapy. I am looking to hear someone immediately. Please don't apply unless you are a Scrapy expert. Start your proposal with the word 'pumpkin' or else it will be ignored.\", 'I want to build a simple chrome extension through which we can fetch the user profile data from Linkedin and group them under names. We want to fetch the following data: Name Email - if possible Contact - if possible Location Designation Company', 'We are looking for someone who would be able to help us with 3-7 (probably more in the future) API and create conectors for it. Then create Python scripts to automatically download and save data to databases via API. Specifically, we need help with these systems: - Google ADs (keyword and campaign data) - Facebook ADs (campaign data from FB) - Instagram API - Adobe Analytics (analytical data about website traffic and performance) - Google Analytics (analytical data about website traffic and performance) It is not necessary to perform all the mentioned systems, it is possible to agree on one or even several parts, from which, of course, the price will depend.', 'I need a person who can scrape Aliexpress products info with requiremnts below - Scrape by category - Able to extract all products per category (currently Aliexpress limit showing pages per category) - Running multi-thread - Bypass blockage by using proxy API - The tool must scrape at least 4 million products a day - Save data to mongoDB, filter duplication while importing', 'We are looking for the services of a Web Scraper. Candidates with relevant experience are encouraged to apply. Other Information will be provided at hiring time']","type":"string","collapse":true,"$$hashKey":"object:998"},{"name":"df","data":"","type":"string","collapse":true,"$$hashKey":"object:999"},{"name":"url","data":"['https://www.upwork.com/job/Build-Dashboard-using-Scraped-Data-from-Coinmarketcap-com_~01cee640682cd0bea8/', 'https://www.upwork.com/job/Developer-needed-create-quot-scraping-quot-software-pull-daily-lawsuits-filed_~01ea1d5a73c605ddc5/', 'https://www.upwork.com/job/Data-Entry-and-Web-Scraping_~019a79f57b4a2f3ebc/', 'https://www.upwork.com/job/experto-web-scraping_~01da6c70ae4771c4ae/', 'https://www.upwork.com/job/Collect-data-from-various-webpages-via-Python-script_~018838140d5e08ea98/', 'https://www.upwork.com/job/Web-scraping-Script_~01532ec8e6709bd331/', 'https://www.upwork.com/job/Water-utility-database-research_~010c4fb6461015d52b/', 'https://www.upwork.com/job/Data-scraping-mywsba_~0165516a6dcc7981a7/', 'https://www.upwork.com/job/Data-List-Sales-Contacts-for-Engineering-Consulting-Contacts_~01ce177d032674abc2/', 'https://www.upwork.com/job/Build-webscraper-across-multiple-pages-with-Excel-Sheet-the-output_~01bd5dd87a9a7137a5/', 'https://www.upwork.com/job/Python-Developers-needed-for-long-term-project_~01ef93e7618ea7b404/', 'https://www.upwork.com/job/Online-Data-Search-Websites-Lead-Generation-Data-Mining-Web-Scraping_~015831c9f9b2bfba1d/', 'https://www.upwork.com/job/Database-creation-scraping_~01bb7663c59a250661/', 'https://www.upwork.com/job/Web-Application-for-B2B-Sourcing_~019c73f1e447a753b4/', 'https://www.upwork.com/job/Web-scrape_~01c42d497a406ce328/', 'https://www.upwork.com/job/Data-mining-specialist-find-non-for-profit-organizations_~01359681ff924016bd/', 'https://www.upwork.com/job/Python-developer-for-selenium_~012229dea37eb81a7e/', 'https://www.upwork.com/job/Looking-info-based-list-2679-companies_~0171e18b028bc748b4/', 'https://www.upwork.com/job/Login-authentication-checker_~012ef6bfef3d1a1dfb/', 'https://www.upwork.com/job/Hiring-data-miner-part-full-time-amp-Commercial-Properties_~01f71c4b0e5ca9ef15/', 'https://www.upwork.com/job/Need-data-sources-assessed-for-their-functionality-attribute_~01f8653ac8d2396e75/', 'https://www.upwork.com/job/Python-scraping-bot_~0105cb2455226fa8a1/', 'https://www.upwork.com/job/Extensive-Web-Researcher-needed-locate-Social-media-Influencers-details_~01703b3a6a3418a8e8/', 'https://www.upwork.com/job/Data-Mining-Expert-Needed-Extract-the-User-Data-from-Websites_~0163eec5fbaffbd071/', 'https://www.upwork.com/job/Web-scrapping_~0152ba7a602adbddd1/', 'https://www.upwork.com/job/Collect-the-Company-amp-Contact-information_~01c265b8c8362a49fe/', 'https://www.upwork.com/job/Lead-list-builder-needed-for-leads-from-linkedin_~01fb7a666f85bbac04/', 'https://www.upwork.com/job/Developer-needed-for-Scraping-complicated-live-stream-website_~01e08a1f2da92c880c/', 'https://www.upwork.com/job/Need-find-merchant-provider-website-using_~01422776e3118935fd/', 'https://www.upwork.com/job/Transfer-Excel-Spreadsheets-onto-website_~016e3c5f7369d74158/', 'https://www.upwork.com/job/Develop-and-Scrape-Data-from-Website_~01ded517b4182811a8/', 'https://www.upwork.com/job/Lead-Generation-Shoe-Importers_~01b9bd794ccd171fab/', 'https://www.upwork.com/job/Website-scraping-into-excel-multiple-times-per-minute_~01e02a34be43beae1f/', 'https://www.upwork.com/job/Developer-needed-scrape-university-websites_~0144f50d8a7518f267/', 'https://www.upwork.com/job/Looking-for-Automation-Expert_~01dae72ba7c2f56cc7/', 'https://www.upwork.com/job/Web-Scraping-using-Python_~01293fb2f204565ead/', 'https://www.upwork.com/job/Benchmarking-exercise-for-countries_~014e5186f1dac07429/', 'https://www.upwork.com/job/Enrich-contact-data-sheet-with-only-company-data-marketing-profiles-within-each-company_~01e9605808bbb88a11/', 'https://www.upwork.com/job/Generate-list-prospects-leads-companies-using-VOIP-PBX-phone-systems_~01645737f7aa6bde0b/', 'https://www.upwork.com/job/Parser-SBB-train-schedule-Google-Sheet_~0104f72599f6a817fe/', 'https://www.upwork.com/job/eCommerce-website-scrape-with-data-output-Excel-and-image-files_~01b915b2af1ab34fdc/', 'https://www.upwork.com/job/Data-Mining-from-multiple-ecommerce-sites_~0103f148e5b55f18b9/', 'https://www.upwork.com/job/Binance-Smart-Chain-Bot-for-Sniping-BEP20-Tokens-amp-Pre-Launch-Coins_~015217d31f7d798e54/', 'https://www.upwork.com/job/Data-Extraction_~01600619cb779b8e54/', 'https://www.upwork.com/job/Build-Web-Scraper-for-Crexi-com_~013c7ea4ce64cac884/', 'https://www.upwork.com/job/Assistance-with-Scrapy-pulling-data-from-nested-pages_~01058f597cf2b1656c/', 'https://www.upwork.com/job/Chrome-extension-fetch-Linkedin-profile-details_~0158434f075a788bdc/', 'https://www.upwork.com/job/Python-programmer-data-acquisition-from-API_~0104ed6bd266566e99/', 'https://www.upwork.com/job/Developer-who-can-build-Aliexpress-scraper_~01038cea7fd580e0e2/', 'https://www.upwork.com/job/Web-Scrapping-Excel_~0120a0c2570e8d7480/']","type":"string","collapse":true,"$$hashKey":"object:1000"}],"ifs":[]}}